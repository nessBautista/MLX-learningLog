{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traning a simple model implementation with MLX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 85.29496002197266\n",
      "Epoch 100, Loss: 11.495914459228516\n",
      "Epoch 200, Loss: 2.253504753112793\n",
      "Epoch 300, Loss: 0.541222095489502\n",
      "Epoch 400, Loss: 0.14475779235363007\n",
      "Epoch 500, Loss: 0.04126681759953499\n",
      "Epoch 600, Loss: 0.012283291667699814\n",
      "Epoch 700, Loss: 0.003787212772294879\n",
      "Epoch 800, Loss: 0.001215551164932549\n",
      "Epoch 900, Loss: 0.0004181584226898849\n",
      "Epoch 0, Loss: 0.000166180485393852\n",
      "Epoch 100, Loss: 8.530314516974613e-05\n",
      "Epoch 200, Loss: 5.899957977817394e-05\n",
      "Epoch 300, Loss: 5.034621790400706e-05\n",
      "Epoch 400, Loss: 4.747147613670677e-05\n",
      "Epoch 500, Loss: 4.6507539082085714e-05\n",
      "Epoch 600, Loss: 4.618187085725367e-05\n",
      "Epoch 700, Loss: 4.6071159886196256e-05\n",
      "Epoch 800, Loss: 4.603311390383169e-05\n",
      "Epoch 900, Loss: 4.601995897246525e-05\n"
     ]
    }
   ],
   "source": [
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "import mlx.optimizers as optim\n",
    "num_features = 100\n",
    "num_examples = 1_000\n",
    "\n",
    "# Ground truth parameters\n",
    "w_star = mx.random.normal((num_features,))\n",
    "\n",
    "# Design matrix and labels with Gaussian noise\n",
    "X = mx.random.normal((num_examples, num_features))\n",
    "eps = 1e-2 * mx.random.normal((num_examples,))\n",
    "y = X @ w_star + eps\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = mx.random.normal((num_features,))\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return x @ self.weights\n",
    "\n",
    "model = LinearRegression()\n",
    "loss_fn = lambda: 0.5 * mx.mean(mx.square(model(X) - y))\n",
    "optimizer = optim.SGD(learning_rate=0.01)\n",
    "# Change the loss function to accept the required arguments\n",
    "def loss_fn(model, X, y):\n",
    "    return 0.5 * mx.mean(mx.square(model(X) - y))\n",
    "\n",
    "# Create the loss_and_grad function\n",
    "loss_and_grad_fn = mx.value_and_grad(loss_fn)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1000):\n",
    "    loss, grads = loss_and_grad_fn(model, X, y)\n",
    "    optimizer.update(model, grads)\n",
    "    mx.eval(model.parameters(), optimizer.state)\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1000):\n",
    "    loss, grads = loss_and_grad_fn(model, X, y)\n",
    "    optimizer.update(model, grads)\n",
    "    mx.eval(model.parameters(), optimizer.state)\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss}\")  # Remove the () after loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core ML Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LinearRegression' object has no attribute 'to_mil'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m input_sample \u001b[38;5;241m=\u001b[39m mx\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal((\u001b[38;5;241m1\u001b[39m, num_features))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Hypothetical: Convert MLX model to a MIL program.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# (Make sure your MLX framework supports such an export, e.g., via a `to_mil()` method.)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m mil_program \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_mil\u001b[49m()  \n\u001b[1;32m      9\u001b[0m mlmodel \u001b[38;5;241m=\u001b[39m ct\u001b[38;5;241m.\u001b[39mconvert(\n\u001b[1;32m     10\u001b[0m     mil_program,\n\u001b[1;32m     11\u001b[0m     source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmilinternal\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Now the input IS a MIL program.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     inputs\u001b[38;5;241m=\u001b[39m[ct\u001b[38;5;241m.\u001b[39mTensorType(shape\u001b[38;5;241m=\u001b[39minput_sample\u001b[38;5;241m.\u001b[39mshape, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m)],\n\u001b[1;32m     13\u001b[0m     minimum_deployment_target\u001b[38;5;241m=\u001b[39mct\u001b[38;5;241m.\u001b[39mtarget\u001b[38;5;241m.\u001b[39miOS14  \u001b[38;5;66;03m# Optionally lower deployment target.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m mlmodel\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinearRegression.mlmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.8/lib/python3.11/site-packages/mlx/nn/layers/base.py:103\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mModule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LinearRegression' object has no attribute 'to_mil'"
     ]
    }
   ],
   "source": [
    "import coremltools as ct\n",
    "\n",
    "input_sample = mx.random.normal((1, num_features))\n",
    "\n",
    "# Specify the source explicitly (e.g., \"milinternal\" if using MLX/MIL)\n",
    "mlmodel = ct.convert(\n",
    "    model,\n",
    "    source=\"milinternal\",\n",
    "    inputs=[ct.TensorType(shape=input_sample.shape, name=\"input\")]\n",
    ")\n",
    "mlmodel.save(\"LinearRegression.mlmodel\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
